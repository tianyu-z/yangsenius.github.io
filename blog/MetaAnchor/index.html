<!DOCTYPE html><html><head>
      <title>MetaAnchor_ Learning to Detect Objects with Customized Anchors &#x8BBA;&#x6587;&#x89E3;&#x8BFB;</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      
        <script type="text/x-mathjax-config">
          MathJax.Hub.Config({"extensions":["tex2jax.js"],"jax":["input/TeX","output/HTML-CSS"],"messageStyle":"none","tex2jax":{"processEnvironments":false,"processEscapes":true,"inlineMath":[["$","$"],["\\(","\\)"]],"displayMath":[["$$","$$"],["\\[","\\]"]]},"TeX":{"extensions":["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]},"HTML-CSS":{"availableFonts":["TeX"]}});
        </script>
        <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js"></script>
        
        <!--  head   --><!--  网页head   --><!--  网页头部分   -->
        <!--  head   --><!--  网页head   --><!--  网页头部分   -->
        <script type="text/javascript" src="/html_style/head.js"></script>
        <!--  head   --><!--  网页head   --><!--  网页头部分   -->
        <!--  head   --><!--  网页head   --><!--  网页头部分   -->
      
      
      
      
      
      

      <style> 
      /**
 * prism.js Github theme based on GitHub's theme.
 * @author Sam Clarke
 */
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
  /* border: 1px solid #ddd; */
  border-radius: 3px;
  /* background: #fff; */
  background: #f5f5f5;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


/* JSON */
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

/* CSS */
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

/* YAML */
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

/* Ruby */
.language-ruby .token.function {
  color: #333;
}

/* Markdown */
.language-markdown .token.url {
  color: #795da3;
}

/* Makefile */
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

/* Bash */
.language-bash .token.keyword {
  color: #0086b3;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */
 
      </style>
    </head>
    <body for="html-export">
        
        <!--  网页主题部分   --><!--  网页主题部分   --><!--  网页主题部分   --><!--  网页主题部分   -->
        <!--  网页主题部分   --><!--  网页主题部分   --><!--  网页主题部分   --><!--  网页主题部分   -->
        <script type="text/javascript" src="/html_style/body.js"></script>
        <!--  网页主题部分   --><!--  网页主题部分   --><!--  网页主题部分   --><!--  网页主题部分   -->
        <!--  网页主题部分   --><!--  网页主题部分   --><!--  网页主题部分   --><!--  网页主题部分   -->

      <div class="mume markdown-preview   ">
      <h1>MetaAnchor: Learning to Detect Objects with Customized Anchors</h1>
<p><a href="http://papers.nips.cc/paper/7315-metaanchor-learning-to-detect-objects-with-customized-anchors">NeuIPS 2018</a></p>
<blockquote>
<p>&#x539F;&#x521B;&#x535A;&#x6587; &#x8F6C;&#x8F7D;&#x8BF7;&#x6CE8;&#x660E;&#x6765;&#x6E90;</p>
</blockquote>
<p>&#x4E00;&#x822C;&#x76EE;&#x6807;&#x68C0;&#x6D4B;&#x65B9;&#x6CD5;&#x4E2D;&#x7684;Anchors&#x7684;&#x751F;&#x6210;&#x662F;&#x6765;&#x81EA;&#x4E8E;&#x4EBA;&#x7C7B;&#x7684;&#x5148;&#x9A8C;&#x77E5;&#x8BC6;:<span class="mathjax-exps">$b_i\in \mathcal{B} \ which \ is \ predefined \ by \ human$</span>&#xFF08;<span class="mathjax-exps">$\mathcal{B}$</span>&#x5C5E;&#x4E8E; <span class="mathjax-exps">${prior}$</span> <span class="mathjax-exps">$i$</span>&#x4EE3;&#x8868;&#x7F51;&#x683C;&#x6216;&#x951A;&#x70B9;&#xFF09;&#xFF0C;&#x5373;</p>
<ul>
<li>&#x901A;&#x8FC7;&#x56FA;&#x5B9A;&#x951A;&#x70B9;&#xFF0C;&#x6216;&#x8005;&#x5212;&#x5206;&#x7F51;&#x683C;&#xFF0C;&#x751F;&#x6210;&#x4E00;&#x5B9A;&#x5F62;&#x72B6;&#x548C;&#x5C3A;&#x5BF8;&#x7684;Anchor Bboxes &#x6765;&#x4F5C;&#x4E3A;&#x5019;&#x9009;&#x68C0;&#x6D4B;&#x533A;&#x57DF;,&#x63D0;&#x53D6;&#x5BF9;&#x5E94;&#x4F4D;&#x7F6E;&#x7684;&#x56FE;&#x50CF;&#x7279;&#x5F81;&#xFF0C;</li>
</ul>
<p>&#x5148;&#x9A8C;&#x5F80;&#x5F80;&#x4EE3;&#x8868;&#x8BBE;&#x8BA1;&#x4EBA;&#x5458;&#x5728;&#x6784;&#x601D;&#x6700;&#x521D;&#x7684;&#x6734;&#x7D20;&#x60F3;&#x6CD5;&#xFF0C;&#x6765;&#x6E90;&#x4E8E;&#x76F4;&#x89C9;&#xFF0C;&#x5E76;&#x628A;&#x8FD9;&#x79CD;&#x76F4;&#x89C9;&#x878D;&#x5408;&#x5728;&#x8BBE;&#x8BA1;&#x8005;&#x7684;&#x5B9E;&#x73B0;&#x8FC7;&#x7A0B;&#x4E0E;&#x4EE3;&#x7801;&#x4E2D;&#x3002;</p>
<p>&#x4E0B;&#x9762;&#x4E3E;&#x4E24;&#x4E2A;&#x4F8B;&#x5B50;&#x3002;</p>
<h3 class="mume-header" id="%E5%9C%A8faster-rcnn%E4%B8%AD">&#x5728;Faster Rcnn&#x4E2D;</h3>

<p>&#x5BF9;&#x8F93;&#x51FA;&#x7684;(W,H,d)&#x7EF4;Conv map&#x8FDB;&#x884C;&#x6ED1;&#x52A8;&#x904D;&#x5386;&#xFF0C;&#x6BCF;&#x4E2A;&#x6ED1;&#x7A97;&#x8F93;&#x51FA;&#x4E00;&#x4E2A;&#x7279;&#x5F81;&#x5411;&#x91CF;WxH&#x4E2A;d&#x7EF4;&#x7684;&#x7279;&#x5F81;&#x5411;&#x91CF;</p>
<p>&#x6839;&#x636E;&#x6839;&#x636E;&#x611F;&#x53D7;&#x91CE;&#x4E2D;&#x5FC3;&#x4E0D;&#x53D8;&#x7684;&#x539F;&#x7406;&#xFF0C;&#x6BCF;&#x4E2A;&#x6ED1;&#x7A97;&#x4E2D;&#x5FC3;&#x5BF9;&#x5E94;&#x539F;&#x56FE;&#x7684;anchor&#x951A;&#x70B9;&#x6216;&#x8005;&#x8BF4;anchor bboxes&#x7684;&#x4E2D;&#x5FC3;&#x3002;</p>
<p>&#x6BCF;&#x4E2A;&#x951A;&#x70B9;&#x6620;&#x5C04;&#x5230;&#x539F;&#x56FE;&#xFF0C;&#x5B9E;&#x9645;&#x4E0A;&#x5BF9;&#x5E94;&#x7740;&#x6765;&#x81EA;3x3(3&#x79CD;&#x7279;&#x5B9A;&#x7684;&#x5C3A;&#x5EA6;x3&#x4E2A;&#x7279;&#x5B9A;&#x7684;&#x5F62;&#x72B6;)&#x4E2A;&#x7684;anchor boxes&#xFF0C;&#x6211;&#x4EEC;&#x8BA4;&#x4E3A;&#x8FD9;9&#x4E2A;anchor bboxes&#x7ECF;&#x8FC7;&#x7279;&#x5F81;&#x63D0;&#x53D6;&#x5F97;&#x5230;&#x7684;&#x5177;&#x6709;&#x5C3A;&#x5EA6;&#x4E0D;&#x53D8;&#x6027;&#x7684;&#x7279;&#x5F81;&#x5411;&#x91CF;&#xFF0C;&#x8FD9;&#x4E9B;anchor bboxes&#x610F;&#x5473;&#x7740;proposals&#x3002;</p>
<p>&#x7136;&#x540E;&#x4F5C;&#x8005;&#x4F7F;&#x7528;&#x5148;&#x9A8C;&#x89C4;&#x5B9A;&#xFF1A;proposal&#x4E0E;GTbbox iou&#x5927;&#x4E8E;&#x67D0;&#x4E2A;&#x9608;&#x503C;&#xFF08;0.7&#xFF09;&#x8BA4;&#x4E3A;&#x662F;&#x6B63;&#x6837;&#x672C;&#xFF0C;&#x5C0F;&#x4E8E;&#x67D0;&#x4E2A;&#x9608;&#x503C;&#xFF08;0.3&#xFF09;&#x4E3A;&#x8D1F;&#x6837;&#x672C;&#xFF0C;&#x5176;&#x4F59;&#x7684;&#x4E0D;&#x53C2;&#x4E0E;&#x8BAD;&#x7EC3;&#xFF01;&#x5373;&#x7ED9;&#x8FD9;&#x4E9B;proposals&#x505A;&#x6807;&#x7B7E;&#xFF01;</p>
<p>&#x7136;&#x540E;&#x628A;&#x8FD9;&#x4E9B;&#x6B63;&#x8D1F;&#x6837;&#x672C;&#x9001;&#x5165;RPN&#x8FDB;&#x884C;&#x8BAD;&#x7EC3;&#x3002;</p>
<p>loss&#x7531;regression&#x548C;classification&#x4E24;&#x4E2A;loss&#x6784;&#x6210;&#xFF0C;&#x5373;&#x9884;&#x6D4B;proposal&#x7684;&#x4E2D;&#x5FC3;&#x4F4D;&#x7F6E;&#x548C;&#x5BBD;&#x9AD8;&#xFF0C;&#x4EE5;&#x53CA;proposal&#x5C5E;&#x4E8E;&#x524D;&#x666F;or&#x80CC;&#x666F;</p>
<p>&#x6CE8;&#x610F;&#xFF1A;&#x8FD9;&#x91CC;&#x7684;regression loss&#x5305;&#x542B;&#x4E09;&#x4E2A;&#x5750;&#x6807;&#xFF1A;&#x9884;&#x6D4B;bbox&#x3001;anchor bboxes&#x3001;GT&#x2014;&#x2014;bboxes,loss&#x51FD;&#x6570;&#x7684;&#x76EE;&#x6807;&#x662F;&#xFF0C;&#x7F29;&#x5C0F;  [&#x9884;&#x6D4B;bbox&#x4E0E;anchor bboxes&#x76F8;&#x5BF9;&#x504F;&#x79FB;] &#x548C;[gt_bbox&#x4E0E;anchor bboxes&#x76F8;&#x5BF9;&#x504F;&#x79FB;]&#x4E4B;&#x95F4;&#x7684;&#x5DEE;&#x8DDD;&#xFF01;</p>
<p>&#x7ECF;&#x8FC7;RPN&#x7B5B;&#x9009;&#x540E;&#x7684;Proposal&#x7684;&#x7279;&#x5F81;&#x56FE;&#x7684;&#x5C3A;&#x5BF8;&#x5927;&#x5C0F;&#x662F;&#x4E0D;&#x4E00;&#x81F4;&#x7684;&#xFF0C;&#x7ECF;&#x8FC7;ROIPOOling&#x5F97;&#x5230;&#x7279;&#x5F81;&#x7EF4;&#x5EA6;&#x4E00;&#x81F4;&#x7684;&#x7279;&#x5F81;&#xFF0C;&#x4F7F;&#x7528;&#x4E0E;RPN&#x5171;&#x4EAB;&#x5377;&#x79EF;&#x7684;Fast Rcnn&#x8FDB;&#x884C;&#x8FDB;&#x4E00;&#x6B65;&#x7684;&#x5206;&#x7C7B;&#x548C;&#x56DE;&#x5F52;&#x3002;</p>
<h3 class="mume-header" id="%E5%9C%A8yolo%E4%B8%AD">&#x5728;yolo&#x4E2D;</h3>

<p>&#x5BF9;&#x4EFB;&#x610F;&#x8F93;&#x5165;&#x5C3A;&#x5BF8;&#x7684;&#x56FE;&#x50CF;&#x5212;&#x5206;&#x4E3A;<span class="mathjax-exps">$s*s$</span>&#x4E2A;&#x7F51;&#x683C;</p>
<p>&#x6BCF;&#x4E2A;&#x7F51;&#x683C;&#x9884;&#x6D4B;B&#x4E2A;bbox&#x7684;4&#x4E2A;&#x4F4D;&#x7F6E;&#x548C;1&#x4E2A;&#x7F6E;&#x4FE1;&#x5EA6;</p>
<ul>
<li>(confidence&#x4EE3;&#x8868;&#x4E86;&#x6240;&#x9884;&#x6D4B;&#x7684;box&#x4E2D;&#x542B;&#x6709;object&#x7684;&#x7F6E;&#x4FE1;&#x5EA6;&#x548C;&#x8FD9;&#x4E2A;box&#x9884;&#x6D4B;&#x7684;&#x6709;&#x591A;&#x51C6;&#x4E24;&#x91CD;&#x4FE1;&#x606F;,object&#x843D;&#x5728;&#x4E00;&#x4E2A;grid cell&#x91CC;&#xFF0C;&#x7B2C;&#x4E00;&#x9879;&#x53D6;1&#xFF0C;&#x5426;&#x5219;&#x53D6;0&#x3002; &#x7B2C;&#x4E8C;&#x9879;&#x662F;&#x9884;&#x6D4B;&#x7684;bounding box&#x548C;&#x5B9E;&#x9645;&#x7684;groundtruth&#x4E4B;&#x95F4;&#x7684;IoU&#x503C;)</li>
</ul>
<p>&#x6BCF;&#x4E2A;&#x7F51;&#x683C;&#x540C;&#x65F6;&#x9884;&#x6D4B;C&#x4E2A;&#x7C7B;&#x7684;&#x7C7B;&#x522B;&#x4FE1;&#x606F;(&#x6BCF;&#x4E2A;&#x7F51;&#x683C;&#x5C5E;&#x4E8E;&#x7684;&#x67D0;&#x7C7B;&#x522B;&#x7684;&#x6761;&#x4EF6;&#x6982;&#x7387;)</p>
<p>&#x5373;&#x5BF9;&#x4E8E;&#x4E00;&#x4E2A;&#x8F93;&#x5165;&#x56FE;&#x50CF;&#xFF0C;&#x5176;&#x8F93;&#x51FA;&#x7684;&#x5F20;&#x91CF;&#x4E3A; <span class="mathjax-exps">$S*S*&#xFF08;B*5+C&#xFF09;$</span></p>
<h2 class="mume-header" id="%E5%9C%A8%E8%BF%99%E9%87%8C%E6%9C%89%E5%BF%85%E8%A6%81%E8%AF%B4%E6%98%8E%E8%BF%99%E9%87%8Canchor%E5%85%88%E9%AA%8C%E7%9A%84%E5%90%AB%E4%B9%89%E5%8D%B3%E8%A6%81%E6%8A%8Aanchor%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%BD%8D%E7%BD%AE-%E5%B0%BA%E5%AF%B8-%E7%B1%BB%E6%AF%94%E8%95%B4%E5%90%AB%E5%9C%A8anchor-function%E7%9A%84%E8%AE%BE%E8%AE%A1%E4%B8%AD%E8%80%8C%E4%B8%8D%E8%83%BD%E6%88%90%E4%B8%BA%E4%B8%80%E4%B8%AA%E7%8B%AC%E7%AB%8B%E7%9A%84%E6%A8%A1%E5%9D%97">&#x5728;&#x8FD9;&#x91CC;&#xFF0C;&#x6709;&#x5FC5;&#x8981;&#x8BF4;&#x660E;&#xFF0C;&#x8FD9;&#x91CC;&#x201C;Anchor&#x5148;&#x9A8C;&#x201D;&#x7684;&#x542B;&#x4E49;&#xFF0C;&#x5373;&#xFF1A;&#x8981;&#x628A;anchor&#x7684;&#x8BBE;&#x8BA1;&#xFF08;&#x4F4D;&#x7F6E;&#x3001;&#x5C3A;&#x5BF8;&#x3001;&#x7C7B;&#x6BD4;&#xFF09;&#x8574;&#x542B;&#x5728;anchor function&#x7684;&#x8BBE;&#x8BA1;&#x4E2D;&#xFF0C;&#x800C;&#x4E0D;&#x80FD;&#x6210;&#x4E3A;&#x4E00;&#x4E2A;&#x72EC;&#x7ACB;&#x7684;&#x6A21;&#x5757;</h2>

<h4 class="mume-header" id="%E4%BD%9C%E8%80%85%E6%80%BB%E7%BB%93%E4%BA%86%E4%B8%80%E4%B8%AA%E8%BE%83%E4%B8%BA%E4%B8%80%E8%88%AC%E7%9A%84%E5%BD%A2%E5%BC%8F">&#x4F5C;&#x8005;&#x603B;&#x7ED3;&#x4E86;&#x4E00;&#x4E2A;&#x8F83;&#x4E3A;&#x4E00;&#x822C;&#x7684;&#x5F62;&#x5F0F;&#xFF1A;</h4>

<p></p><div class="mathjax-exps">$$\mathcal{F}_{b_i}(\mathbf{x}; \theta_i)=\left( \mathcal{F}^{cls}_{b_i}(\mathbf{x}; \theta^{cls}_i), \mathcal{F}^{reg}_{b_i}(\mathbf{x}; \theta^{reg}_i)\right)(1)$$</div><p></p>
<p>&#x5224;&#x65AD;&#xFF1A;</p>
<ol>
<li>&#x6BCF;&#x4E2A;&#x5019;&#x9009;&#x533A;&#x57DF;&#x7684;&#x4E0E;&#x771F;&#x5B9E;bbox&#xFF08;&#x5982;&#x679C;&#x6709;&#xFF09;&#x7684;&#x76F8;&#x5BF9;&#x4F4D;&#x7F6E;<span class="mathjax-exps">$\mathcal{F}^{reg}_{b_i}(\mathord{\cdot})$</span></li>
<li>&#x6BCF;&#x4E2A;&#x5019;&#x9009;&#x533A;&#x57DF;&#x7684;&#x7C7B;&#x522B;&#x7F6E;&#x4FE1;&#x6982;&#x7387;<span class="mathjax-exps">$\mathcal{F}^{cls}_{b_i}(\mathord{\cdot})$</span></li>
</ol>
<p>&#x672C;&#x7BC7;&#x6587;&#x7AE0;&#xFF0C;&#x4F5C;&#x8005;&#x4F7F;&#x7528;&#x7684;Anchor Function &#x662F;&#x4ECE;&#x5148;&#x9A8C;&#x7684;<span class="mathjax-exps">$b_i$</span>&#x52A8;&#x6001;&#x751F;&#x6210;&#x7684;,&#x901A;&#x8FC7;&#x5982;&#x4E0B;&#x51FD;&#x6570;&#xFF1A;</p>
<p></p><div class="mathjax-exps">$$\mathcal{F}_{b_i}=\mathcal{G}\left(b_i; w \right)(2)$$</div><p></p>
<blockquote>
<p><span class="mathjax-exps">$\mathcal{G}(\mathord{\cdot})$</span> is called <span class="mathjax-exps">${anchor \ function \ generator}$</span> which maps any bounding box prior <span class="mathjax-exps">$b_i$</span> to the corresponding anchor function <span class="mathjax-exps">$\mathcal{F}_{b_i}$</span>; and <span class="mathjax-exps">$w$</span> represents the parameters. Note that in MetaAnchor the prior set <span class="mathjax-exps">$\mathcal{B}$</span> is not necessarily predefined; instead, it works as a \textbf{customized} manner -- during inference, users could specify any anchor boxes, generate the corresponding anchor functions and use the latter to predict object boxes.</p>
</blockquote>
<p>&#x4E0A;&#x9762;&#x662F;&#x4F5C;&#x8005;&#x7684;&#x539F;&#x8BDD;&#xFF0C;&#x6211;&#x89C9;&#x5F97;&#x8FD9;&#x4E2A;&#x60F3;&#x6CD5;&#x8FD8;&#x662F;&#x975E;&#x5E38;&#x5177;&#x6709;&#x542F;&#x53D1;&#x6027;&#x7684;&#x3002;&#x6211;&#x7684;&#x7406;&#x89E3;&#x662F;&#xFF1A;</p>
<p>&#x6211;&#x4EEC;&#x4E0D;&#x662F;&#x5148;&#x76F2;&#x76EE;&#x5730;&#x751F;&#x6210;&#x5927;&#x91CF;&#x7684;Anchor&#x6765;&#x5224;&#x65AD;&#x662F;&#x5426;&#x629B;&#x5F03;&#xFF0C;&#x800C;&#x662F;&#x6839;&#x636E;&#x540E;&#x9762;<strong>&#x63A8;&#x7406;&#x65F6;</strong>&#x7684;&#x9700;&#x8981;&#xFF0C;&#x5728;&#x5BF9;&#x5E94;&#x7684;&#x4F4D;&#x7F6E;&#x751F;&#x6210;&#x7279;&#x5B9A;&#x7684;anchor boxes&#xFF0C;&#x7136;&#x540E;&#x751F;&#x6210;anchor function&#x6765;&#x9884;&#x6D4B;&#x7269;&#x4F53;bbox&#xFF0C;&#x8FD9;&#x6837;&#x5C31;&#x907F;&#x514D;&#x4E86;&#x5927;&#x91CF;&#x65E0;&#x5173;&#x7684;&#x5019;&#x9009;&#x6846;&#xFF1F;&#x8FD9;&#x662F;&#x6211;&#x7684;&#x7406;&#x89E3;&#xFF0C;&#x4E0D;&#x77E5;&#x9053;&#x5BF9;&#x4E0D;&#x5BF9;&#xFF0C;&#x63A5;&#x7740;&#x8BFB;&#x8BBA;&#x6587;~</p>
<ul>
<li>
<p>&#x201C;default boxes&#x201D; , &#x201C;priors&#x201D;  or &#x201C;grid cells&#x201D; &#x7ECF;&#x5E38;&#x4F5C;&#x4E3A;&#x4E00;&#x4E2A;&#x9ED8;&#x8BA4;&#x7684;&#x65B9;&#x6CD5;&#x3002;&#x5F88;&#x591A;&#x4EFB;&#x52A1;&#x9700;&#x8981;&#x4F60;&#x5728;&#x8BBE;&#x8BA1;achor&#x7684;&#x5927;&#x5C0F;&#x3001;&#x5C3A;&#x5BF8;&#x3001;&#x4F4D;&#x7F6E;&#x65F6;&#x9700;&#x8981;&#x5C0F;&#x5FC3;&#x8C28;&#x614E;&#xFF0C;&#x4E0D;&#x540C;&#x6570;&#x636E;&#x96C6;&#x4E4B;&#x95F4;&#x7684;&#x7269;&#x4F53;bbox&#x5206;&#x5E03;&#x4E5F;&#x4F1A;&#x5F71;&#x54CD;anchor&#x7684;&#x9009;&#x62E9;&#xFF0C;&#x4F46;&#x662F;MetaAnchor&#x7684;&#x65B9;&#x6CD5;&#x5C31;&#x4E0D;&#x7528;&#x8003;&#x8651;&#x8FD9;&#x4E2A;&#x95EE;&#x9898;&#x3002;</p>
</li>
<li>
<p>&#x53D7;&#x5230; Learning to learn&#x3001;few shot learning &#x3001;transfer learning&#x7684;&#x542F;&#x53D1;&#xFF1A;&#x6709;&#x65F6;&#x5019;&#xFF0C;&#x6211;&#x4EEC;&#x7684;&#x6743;&#x91CD;&#x9884;&#x6D4B;&#x4E0D;&#x662F;&#x901A;&#x8FC7;&#x6A21;&#x578B;&#x672C;&#x8EAB;&#x6765;&#x5B66;&#x4E60;&#xFF0C;&#x800C;&#x662F;&#x901A;&#x8FC7;&#x53E6;&#x4E00;&#x4E2A;&#x7ED3;&#x6784;&#xFF08;&#x6A21;&#x578B;&#xFF09;&#x6765;&#x53D6;&#x9884;&#x6D4B;&#x6743;&#x91CD;&#xFF0C;&#x6BD4;&#x5982;&#xFF08;Learning to learn by gradient descent by gradient descent&#xFF0C;hypernetworks&#x7B49;&#xFF09;&#xFF0C;&#x4F5C;&#x8005;&#x8FD8;&#x62FF;&#x81EA;&#x5DF1;&#x7684;&#x65B9;&#x6CD5;&#x548C;learning to segment everything &#x4F5C;&#x4E86;&#x5BF9;&#x6BD4;&#xFF0C;&#x4F5C;&#x8005;&#x7684;&#x6743;&#x91CD;&#x9884;&#x6D4B;&#x662F;&#x4E3A;&#x4E86;&#x751F;&#x6210;anchor function&#x3002;</p>
</li>
</ul>
<p>&#x4EFF;&#x4F5B;&#xFF0C;&#x8BBA;&#x6587;&#x6700;&#x5173;&#x952E;&#x7684;&#x5C31;&#x662F;&#x5982;&#x4F55;&#x751F;&#x6210;anchor function&#x4E86;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x8FD9;&#x4E2A;&#x51FD;&#x6570;&#x4E86;&#xFF1A;</p>
<p></p><div class="mathjax-exps">$$\mathcal{F}_{b_i}=\mathcal{G}\left(b_i; w \right)$$</div><p></p>
<p>&#x4E0B;&#x9762;&#x8BE6;&#x7EC6;&#x8BA8;&#x8BBA;&#x8FD9;&#x4E2A;&#x673A;&#x5236;&#x3002;</p>
<h2 class="mume-header" id="anchor-function-generator">Anchor Function Generator</h2>

<blockquote>
<p>In MetaAnchor framework, <span class="mathjax-exps">${anchor \ function}$</span> is dynamically generated from the customized box prior (or anchor box) <span class="mathjax-exps">$b_i$</span> rather than fixed function associated with predefined anchor box. So, <span class="mathjax-exps">${anchor \ function \ generator}$</span> <span class="mathjax-exps">$\mathcal{G}(\mathord{\cdot})$</span> (see Equ.2), which maps <span class="mathjax-exps">$b_i$</span> to the corresponding anchor function <span class="mathjax-exps">$\mathcal{F}_{b_i}$</span>, plays a key role in the framework.</p>
</blockquote>
<p>&#x4F5C;&#x8005;&#x5F3A;&#x8C03;&#x4E86;&#x4ECE;<span class="mathjax-exps">$b_i$</span>&#x6620;&#x5C04;&#x5230;anchor function <span class="mathjax-exps">$\mathcal{F}_{b_i}$</span>, &#x8FD9;&#x79CD;&#x6620;&#x5C04;&#x5173;&#x7CFB;&#x662F;&#x56E0;&#x4E3A;<span class="mathjax-exps">$b_i$</span>&#x662F;&#x5E26;&#x7740;&#x4E00;&#x79CD;&#x968F;&#x673A;&#x6027;</p>
<blockquote>
<p>In order to model <span class="mathjax-exps">$\mathcal{G}(\mathord{\cdot})$</span> with neural work, inspired by <a href="">HyperNetworks</a>,<a href="">Learning to segment everything</a>, first we assume that for different <span class="mathjax-exps">$b_i$</span> anchor functions <span class="mathjax-exps">$\mathcal{F}_{b_i}$</span> share the same formulation <span class="mathjax-exps">$\mathcal{F}(\mathord{\cdot})$</span> but have different parameters, which means:</p>
</blockquote>
<p></p><div class="mathjax-exps">$$\mathcal{F}_{b_i}(\mathbf{x}; \theta_i) = \mathcal{F}(\mathbf{x}; \theta_{b_i})$$</div><p></p>
<p>&#x4F5C;&#x8005;&#x5199;&#x8FD9;&#x4E2A;&#x516C;&#x5F0F;&#xFF0C;&#x4F3C;&#x4E4E;&#x60F3;&#x7ED9;&#x51FA;  &#x65E0;&#x8BBA;&#x600E;&#x6837;&#x9009;&#x62E9;<span class="mathjax-exps">$b_i$</span> &#x7684;anchor function&#x7684;&#x4E00;&#x822C;&#x5F62;&#x5F0F;&#x3002;&#x4E3A;&#x4EC0;&#x4E48;&#x8FD9;&#x4E48;&#x505A;&#x5462;&#xFF1F;&#x4E0B;&#x6807;&#x7684;&#x53D8;&#x6362;&#x6709;&#x4EC0;&#x4E48;&#x610F;&#x4E49;&#x5417;&#xFF1F;</p>
<p>&#x6211;&#x6839;&#x636E;&#x540E;&#x9762;&#x7684;&#x5185;&#x5BB9;&#xFF0C;&#x731C;&#x6D4B;&#xFF1A;&#x4E00;&#x822C;anchor function&#x5728;&#x8BBE;&#x8BA1;&#x65F6;&#x662F;&#x8981;&#x8003;&#x8651; anchor<span class="mathjax-exps">$b_i$</span>&#x7684;&#x9884;&#x5B9A;&#x4E49;&#x65B9;&#x5F0F;&#xFF0C;&#x4E5F;&#x5C31;&#x662F;&#x6211;&#x4EEC;&#x8981;&#x6839;&#x636E;&#x4E0D;&#x540C;&#x7684;anchor&#x5148;&#x9A8C;&#xFF0C;&#x5177;&#x4F53;&#x8BBE;&#x8BA1;&#x51FA;&#x76F8;&#x5BF9;&#x5E94;&#x7684;anchor function&#x3002;&#x5982;&#x679C;&#x6211;&#x4EEC;anchor function&#x7684;&#x8BBE;&#x8BA1;&#x80FD;&#x591F;&#x72EC;&#x7ACB;&#x4E8E;anchor<span class="mathjax-exps">$b_i$</span>&#x7684;&#x9884;&#x5B9A;&#x4E49;&#x65B9;&#x5F0F;&#xFF0C;&#x8BA9;anchor<span class="mathjax-exps">$b_i$</span>&#x7684;&#x8BBE;&#x8BA1;&#x53D8;&#x6210;&#x4E00;&#x4E2A;&#x51FD;&#x6570;&#x7684;&#x53EF;&#x5B66;&#x4E60;&#x7684;&#x53C2;&#x6570;&#x5F62;&#x5F0F;&#xFF0C;&#x90A3;&#x4E48;&#x5C31;&#x628A;&#x95EE;&#x9898;&#x8F6C;&#x5316;&#x4E3A;&#x4E00;&#x822C;&#x7684;&#x8D85;&#x53C2;&#x6570;&#x5B66;&#x4E60;&#xFF0C;&#x6216;&#x8005;Meta-learning &#x7684;&#x65B9;&#x5F0F;&#x3002;&#x4E4B;&#x524D;&#x6211;&#x7814;&#x7A76;Learning  to learn by gradient descent by gradient descent&#xFF0C;&#x4F5C;&#x8005;&#x5C31;&#x662F;&#x8BA9;&#x4EBA;&#x5DE5;&#x5E72;&#x9884;&#x8BBE;&#x8BA1;&#x7684;&#x4F18;&#x5316;&#x65B9;&#x5F0F;&#xFF0C;&#x53D8;&#x6210;&#x4E86;&#x53EF;&#x4EE5;&#x5B66;&#x4E60;&#x7684;&#x53C2;&#x6570;&#xFF0C;&#x4E8C;&#x8005;&#x867D;&#x7136;&#x9762;&#x5BF9;&#x7684;&#x95EE;&#x9898;&#x7684;&#x4E0D;&#x4E00;&#x6837;&#xFF0C;&#x4F46;&#x662F;&#x90FD;&#x5305;&#x542B;&#x4E86;&#x4E00;&#x4E2A;&#x5171;&#x540C;&#x7684;&#x601D;&#x60F3;&#xFF1A;</p>
<p>&#x8BA9;&#x4EBA;&#x5DE5;&#x8BBE;&#x8BA1;&#x7684;&#x5148;&#x9A8C;&#x77E5;&#x8BC6;&#xFF0C;&#x8F6C;&#x5316;&#x6210;&#xFF0C;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x53E6;&#x4E00;&#x4E2A;&#x7ED3;&#x6784;&#x6216;&#x6A21;&#x578B;&#x5B66;&#x4E60;&#x7684;&#xFF0C;&#x53C2;&#x6570;&#x5F62;&#x5F0F;&#xFF1A;</p>
<p><strong></strong></p><div class="mathjax-exps"><strong>$$&#x4EBA;&#x5DE5;&#x5148;&#x9A8C;&#x77E5;&#x8BC6; \rightarrow  &#x53EF;&#x5B66;&#x4E60;&#x7684;&#x53C2;&#x6570;&#x5F62;&#x5F0F;$$</strong></div><p></p>
<p>&#x8FD9;&#x4E2A;&#x601D;&#x60F3;&#x548C;&#x6211;&#x4E0A;&#x4E00;&#x7BC7;<a href="https://blog.csdn.net/senius/article/details/84483329">&#x535A;&#x5BA2;:learning to learn</a> &#x6240;&#x6D89;&#x53CA;&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x5728;&#x7406;&#x5FF5;&#x4E0A;&#x4E0D;&#x8C0B;&#x800C;&#x5408;</p>
<p>&#x63A5;&#x7740;&#x770B;&#x8BBA;&#x6587;&#x3002;</p>
<p>&#x8BBA;&#x6587;&#x8BF4;&#x9053;&#xFF1A;</p>
<blockquote>
<p>each anchor function is distinguished only by its parameters <span class="mathjax-exps">$\theta_{b_i}$</span>, anchor function generator could be formulated to predict <span class="mathjax-exps">$\theta_{b_i}$</span> as follows:</p>
</blockquote>
<p></p><div class="mathjax-exps">$$\theta_{b_i} = \mathcal{G}(b_i; w) \\= \theta^* + \mathcal{R}(b_i; w)$$</div><p></p>
<p>&#x5C31;&#x662F;&#x8BF4;&#xFF0C;&#x6BCF;&#x4E2A;anchor function &#x901A;&#x8FC7;&#x53C2;&#x6570; <span class="mathjax-exps">$\theta_{b_i}$</span> &#x6765;&#x552F;&#x4E00;&#x786E;&#x5B9A;(&#x6211;&#x7684;&#x7406;&#x89E3;&#x5E94;&#x8BE5;&#x6CA1;&#x9519;)&#xFF0C;&#x5176;&#x4E2D;<span class="mathjax-exps">$\theta^*$</span>&#x4EE3;&#x8868;&#x5171;&#x4EAB;&#x53C2;&#x6570;&#xFF08;&#x72EC;&#x7ACB;&#x4E8E;<span class="mathjax-exps">${b_i}$</span>&#xFF0C;&#x5E76;&#x4E14;&#x53EF;&#x4EE5;&#x5B66;&#x4E60;&#xFF09;&#xFF0C;&#x6B8B;&#x5DEE;&#x9879;<span class="mathjax-exps">$\mathcal{R}(b_i; w)$</span>&#x4F9D;&#x8D56;&#x4E8E; anchor bbox <span class="mathjax-exps">${b_i}$</span></p>
<p>&#x7136;&#x540E;<span class="mathjax-exps">$\mathcal{R}(b_i; w)$</span>&#x4F7F;&#x7528;&#x4E00;&#x4E2A;&#x7B80;&#x5355;&#x7684;&#x4E24;&#x5C42;&#x5168;&#x8FDE;&#x63A5;&#x7F51;&#x7EDC;&#x6765;&#x8868;&#x793A;&#xFF1A;</p>
<p></p><div class="mathjax-exps">$$\mathcal{R}(b_i, w) = \mathrm{W}_2 \sigma \left( \mathrm{W}_1 b_i \right)$$</div><p></p>
<p>&#x4F5C;&#x8005;&#x8FD8;&#x8003;&#x8651;&#x628A;&#x56FE;&#x50CF;&#x7279;&#x5F81;&#x5F15;&#x5165;&#x5230;&#x53C2;&#x6570; <span class="mathjax-exps">$\theta_{b_i}$</span>&#x7684;&#x5B66;&#x4E60;&#x4E2D;&#xFF1A;</p>
<p></p><div class="mathjax-exps">$$\theta_{b_i} = \mathcal{G}(b_i; \mathbf{x}, w) \\ 	= \theta^* + \mathrm{W}_2 \sigma \left(     \mathrm{W}_{11} b_i + \mathrm{W}_{12} r(\mathbf{x})     \right)$$</div><p></p>
<p><span class="mathjax-exps">$r(\mathord{\cdot})$</span> &#x7528;&#x6765;&#x7ED9; <span class="mathjax-exps">$\mathbf{x}$</span>&#x964D;&#x7EF4;;</p>
<p>&#x4EE5;&#x4E0A;&#x5C31;&#x662F;&#x8BBA;&#x6587;&#x7684;&#x7406;&#x8BBA;&#x601D;&#x60F3;&#x4E86;&#xFF01;</p>
<p><img src="https://img-blog.csdnimg.cn/2018121317400085.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Nlbml1cw==,size_16,color_FFFFFF,t_70" alt="&#x5728;&#x8FD9;&#x91CC;&#x63D2;&#x5165;&#x56FE;&#x7247;&#x63CF;&#x8FF0;"></p>
<h2 class="mume-header" id="%E5%85%B7%E4%BD%93%E5%AE%9E%E6%96%BD%E7%BB%86%E8%8A%82%E7%BB%93%E5%90%88retinanet%E4%BB%A3%E7%A0%81%E8%AE%A9%E6%88%91%E4%BB%AC%E6%9D%A5%E6%84%9F%E5%8F%97%E4%BB%80%E4%B9%88%E6%98%AFprior%E4%BB%80%E4%B9%88%E6%98%AFmeta">&#x5177;&#x4F53;&#x5B9E;&#x65BD;&#x7EC6;&#x8282;&#xFF0C;&#x7ED3;&#x5408;RetinaNet&#x4EE3;&#x7801;&#xFF0C;&#x8BA9;&#x6211;&#x4EEC;&#x6765;&#x611F;&#x53D7;&#x4EC0;&#x4E48;&#x662F;&#x201C;Prior&#x201D;&#xFF1F;&#x4EC0;&#x4E48;&#x662F;&#x201C;Meta&#x201D;</h2>

<blockquote>
<p>&#x4F5C;&#x8005;&#x6CA1;&#x6709;&#x516C;&#x5E03;&#x81EA;&#x5DF1;&#x7684;&#x6E90;&#x7801;&#x662F;&#x4E00;&#x4EF6;&#x4EE4;&#x4EBA;&#x5934;&#x75BC;&#x7684;&#x4E8B;&#x60C5;&#xFF0C;&#x8FD9;&#x6837;&#x5C31;&#x4E0D;&#x77E5;&#x9053;&#xFF0C;&#x4F5C;&#x8005;&#x662F;&#x5982;&#x4F55;&#x628A;&#x53EF;&#x5B66;&#x4E60;&#x7684;&#x53C2;&#x6570;<span class="mathjax-exps">$\theta_{b_i}$</span>&#x5982;&#x4F55;&#x878D;&#x8FDB;anchor function&#xFF0C;&#x4E0D;&#x8FC7;&#x6211;&#x540E;&#x9762;&#x4F1A;&#x8BD5;&#x56FE;&#x5199;&#x4E00;&#x4E0B;&#x3002;</p>
</blockquote>
<p>&#x4F5C;&#x8005;&#x8BF4;&#xFF0C;&#x8FD9;&#x4E2A;&#x65B9;&#x6CD5;&#x66F4;&#x5B9E;&#x7528;&#x4E8E;one-stage&#x7684;&#x68C0;&#x6D4B;&#x65B9;&#x6CD5;&#x5982; RetinaNet&#xFF0C;yolo&#x7B49;&#xFF0C;two-stage&#x65B9;&#x6CD5;&#x7CBE;&#x5EA6;&#x4F3C;&#x4E4E;&#x53D7;&#x5230;&#x7B2C;&#x4E8C;&#x9636;&#x6BB5;&#xFF08;anchor &#x4E0D;&#x518D;&#x53D1;&#x6325;&#x4F5C;&#x7528;&#xFF09;&#x7684;&#x5B66;&#x4E60;&#x7684;&#x5F71;&#x54CD;&#x66F4;&#x5927;&#x3002;</p>
<p>&#x4F5C;&#x8005;&#x4E3B;&#x8981;&#x8BF4;&#x660E;&#x4E86;MetaAnchor&#x5728;RetinaNet&#x4E0A;&#x7684;&#x4F7F;&#x7528;&#xFF0C;&#x5148;&#x6765;&#x770B;&#x770B;&#x4EC0;&#x4E48;&#x662F;RetianNet&#xFF0C;&#x653E;&#x4E0A;&#x4E00;&#x6BB5;&#x7B80;&#x4ECB;&#x7684;&#x4EE3;&#x7801;</p>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">class</span> <span class="token class-name">RetinaNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    num_anchors <span class="token operator">=</span> <span class="token number">9</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>RetinaNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fpn <span class="token operator">=</span> FPN50<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>num_classes <span class="token operator">=</span> num_classes
        self<span class="token punctuation">.</span>reg_head <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_head<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_anchors<span class="token operator">*</span><span class="token number">4</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cls_head <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_head<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_anchors<span class="token operator">*</span>self<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        fms <span class="token operator">=</span> self<span class="token punctuation">.</span>fpn<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        reg_preds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        cls_preds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> fm <span class="token keyword">in</span> fms<span class="token punctuation">:</span>
            loc_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>loc_head<span class="token punctuation">(</span>fm<span class="token punctuation">)</span>
            cls_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>cls_head<span class="token punctuation">(</span>fm<span class="token punctuation">)</span>
            loc_pred <span class="token operator">=</span> loc_pred<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>                 <span class="token comment"># [N, 9*4,H,W] -&gt; [N,H,W, 9*4] -&gt; [N,H*W*9, 4]</span>
            cls_pred <span class="token operator">=</span> cls_pred<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>  <span class="token comment"># [N,9*20,H,W] -&gt; [N,H,W,9*20] -&gt; [N,H*W*9,20]</span>
            loc_preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loc_pred<span class="token punctuation">)</span>
            cls_preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cls_pred<span class="token punctuation">)</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>loc_preds<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>cls_preds<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_make_head</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> out_planes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> out_planes<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>layers<span class="token punctuation">)</span>

</pre><blockquote>
<p>&#x6CE8;&#xFF1A; &#x4EE5;&#x4E0A;&#x4EE3;&#x7801;&#x6765;&#x81EA;&#x4E8E;<a href="https://github.com/kuangliu/pytorch-retinanet/blob/master/retinanet.py">kuangliu/pytorch-retinanet</a></p>
</blockquote>
<p>&#x4ECE;&#x4EE5;&#x4E0A;&#x4EE3;&#x7801;</p>
<p>_make_head&#xFF08;self, out_planes)</p>
<p>&#x51FD;&#x6570;&#x4E2D;&#x53EF;&#x4EE5;&#x5F97;&#x77E5;&#xFF1A;&#x6211;&#x4EEC;&#x5FC5;&#x987B;&#x628A;anchor&#x7684;&#x6570;&#x91CF;&#x8003;&#x8651;&#x5E76;&#x4F53;&#x73B0;&#x5728;RetinaNet&#x6700;&#x540E;&#x4E00;&#x5C42;&#x5377;&#x79EF;&#x6838;&#x7684;&#x901A;&#x9053;&#x6570;&#x91CF;&#x4E0A;&#x3002;<br>
&#x90A3;&#x4E48;&#x4F5C;&#x4E3A;RetinaNET&#x7F51;&#x7EDC;&#x7ED3;&#x6784;&#x7684;&#x8FD9;&#x4E2A;&#x5377;&#x79EF;&#x6838;&#x90E8;&#x5206;&#xFF0C;&#x5C31;&#x5305;&#x542B;&#x4E86;&#x6211;&#x5148;&#x9A8C;&#x7684;&#x4E00;&#x79CD;&#x8BBE;&#x8BA1;&#xFF08;Anchor&#x7C7B;&#x578B;&#x6570;&#x4E3A;9&#xFF09;&#x3002;</p>
<p>&#x8FD9;&#x6837;&#x505A;&#x7684;&#x5F0A;&#x7AEF;&#x5C31;&#x662F;&#xFF1A;&#x5047;&#x5982;&#x6211;&#x6362;&#x4E86;anchor&#x7684;&#x79CD;&#x7C7B;&#x6216;&#x6570;&#x91CF;&#xFF0C;&#x90A3;&#x4E48;&#x5C31;&#x8981;&#x91CD;&#x65B0;&#x6539;&#x53D8;&#x8FD9;&#x4E2A;&#x5377;&#x79EF;&#x6838;&#x7684;&#x8BBE;&#x8BA1;&#xFF0C;&#x8FDB;&#x800C;&#x5F71;&#x54CD;&#x4E86;&#x7F51;&#x7EDC;&#x7684;&#x7ED3;&#x6784;&#x548C;&#x53C2;&#x6570;&#x5B66;&#x4E60;&#xFF0C;&#x90A3;&#x4E48;&#x8FD9;&#x5C31;&#x610F;&#x5473;&#x7740;&#x6211;&#x5148;&#x524D;&#x5B66;&#x4E60;&#x7684;&#x5BF9;&#x4E8E;9&#x4E2A;Anchor&#x7684;RetinaNet&#x4E0D;&#x518D;&#x5177;&#x6709;&#x4E00;&#x822C;&#x6027;&#xFF0C;&#x4E0D;&#x518D;&#x5177;&#x5907;&#x8FC1;&#x79FB;&#x5B66;&#x4E60;&#x7684;&#x80FD;&#x529B;&#x3002;</p>
<p>&#x5982;&#x679C;&#x6211;&#x60F3;&#xFF0C;&#x6362;&#x4E00;&#x79CD;&#x6570;&#x636E;&#x96C6;bbox&#x7684;&#x5206;&#x5E03;&#xFF0C;&#x6216;&#x8005;&#x6362;&#x4E00;&#x79CD;&#x5148;&#x9A8C;anchor&#x7684;&#x9009;&#x62E9;&#x65B9;&#x5F0F;&#xFF0C;&#x7F51;&#x7EDC;&#x4F9D;&#x65E7;&#x80FD;&#x591F;&#x4F7F;&#x7528;&#x7684;&#x8BDD;&#xFF0C;&#x5C31;&#x5FC5;&#x987B;&#x5C06;anchor&#x7684;&#x5148;&#x9A8C;&#x4ECE;&#x539F;&#x6765;&#x7684;&#x8BBE;&#x8BA1;&#x4E2D;&#x5265;&#x79BB;&#x51FA;&#x6765;&#x4F5C;&#x4E3A;&#x4E00;&#x4E2A;&#x72EC;&#x7ACB;&#x7684;&#x7ED3;&#x6784;&#xFF0C;&#x4ECE;&#x800C;&#x4E0D;&#x5F71;&#x54CD;&#x6574;&#x4F53;&#x7ED3;&#x6784;&#x7684;&#x8BBE;&#x8BA1;&#xFF0C;&#x5E76;&#x4E14;&#x53EF;&#x4EE5;&#x6839;&#x636E;&#x9700;&#x6C42;&#x81EA;&#x5B9A;&#x4E49;&#x4E0D;&#x540C;&#x7684;anchor&#x8BBE;&#x8BA1;&#xFF0C;&#x8FD9;&#x4E5F;&#x5C31;&#x662F;&#x8FD9;&#x7BC7;&#x8BBA;&#x6587;&#x8981;&#x89E3;&#x51B3;&#x7684;&#x95EE;&#x9898;&#xFF0C;&#x5E76;&#x51A0;&#x4EE5;&#x201C;MetaAnchor&#x201D;&#x7684;&#x79F0;&#x53F7;&#xFF0C;&#x5E76;&#x4F7F;&#x7528;&#x4E86;&#x4E00;&#x4E2A;<span class="mathjax-exps">$\mathcal{G}(b_i; w)$</span>&#x7684;anchor function generator</p>
<p>&#x5728;RetianNet &#x7684;&#x539F;&#x8BBE;&#x8BA1;&#x4E2D;&#xFF0C;&#x6BCF;&#x4E2A;detection head&#x6A21;&#x5757;&#x6700;&#x540E;&#x4E00;&#x5C42;&#xFF0C;&#x5BF9;&#x4E8E;&#x9884;&#x5B9A;&#x4E49;&#x7684;3x3&#x4E2D;anchor bboxes &#xFF0C;anchor function&#x4E2D;&#xFF1A;</p>
<ul>
<li>cls&#x6A21;&#x5757;&#x7528;3x3x80&#xFF08;&#x7C7B;&#x522B;&#xFF09;=720&#x4E2A;&#x901A;&#x9053;&#x5377;&#x79EF;&#x6838;&#xFF0C;&#x751F;&#x6210;720&#x7EF4;&#x7684;&#x9884;&#x6D4B;&#x5411;&#x91CF;</li>
<li>reg&#x6A21;&#x5757;&#x6709;3x3x4=36&#x4E2A;&#x901A;&#x9053;&#x5377;&#x79EF;&#x6838;&#xFF0C;&#x751F;&#x6210;36&#x7EF4;&#x7684;&#x9884;&#x6D4B;&#x5411;&#x91CF;</li>
</ul>
<p>&#x800C;&#x5728;&#x4F7F;&#x7528;MetaAnchor&#x540E;&#xFF0C;&#x5C31;&#x964D;&#x6210;&#x4E86;&#xFF1A;</p>
<ul>
<li>cls&#x6A21;&#x5757;&#x6709;80&#xFF08;&#x7C7B;&#x522B;&#xFF09;=80&#x4E2A;&#x901A;&#x9053;&#x5377;&#x79EF;&#x6838;&#xFF0C;&#x751F;&#x6210;80&#x7EF4;&#x7684;&#x9884;&#x6D4B;&#x5411;&#x91CF;</li>
<li>reg&#x6A21;&#x5757;&#x6709;4&#x4E2A;&#x901A;&#x9053;&#x5377;&#x79EF;&#x6838;&#xFF0C;&#x751F;&#x6210;4&#x7EF4;&#x7684;&#x9884;&#x6D4B;&#x5411;&#x91CF;</li>
</ul>
<p>&#x8FD9;&#x5C31;&#x5C31;&#x9700;&#x8981;&#x91CD;&#x65B0;&#x8BBE;&#x8BA1;anchor function&#x3002;&#x6839;&#x636E;&#x81EA;&#x5DF1;&#x5B9A;&#x5236;&#xFF08;customized&#xFF09;&#x7684;anchor bbox<span class="mathjax-exps">${b_i}$</span>&#x9996;&#x5148;&#xFF0C;&#x5E94;&#x8BE5;&#x8003;&#x8651;&#x5982;&#x4F55;&#x7F16;&#x7801;<span class="mathjax-exps">${b_i}$</span>&#xFF0C;&#x5B83;&#x5305;&#x542B;&#x4E86;&#x4F4D;&#x7F6E;&#x3001;&#x5C3A;&#x5BF8;&#x3001;&#x7C7B;&#x522B;&#x4FE1;&#x606F;&#xFF0C;&#x591A;&#x4E8F;&#x4E86;RetianNet&#x7684;&#x5168;&#x5377;&#x79EF;&#x7ED3;&#x6784;&#xFF0C;&#x4F4D;&#x7F6E;&#x5750;&#x6807;&#x4FE1;&#x606F;&#x5DF2;&#x7ECF;&#x5305;&#x542B;&#x5728;Feature map &#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x4F7F;&#x7528;<span class="mathjax-exps">$\mathcal{G}(\cdot)$</span>&#x6765;&#x9884;&#x6D4B;&#x7C7B;&#x522B;&#xFF0C;&#x90A3;&#x4E48;<span class="mathjax-exps">${b_i}$</span>&#x53EA;&#x9700;&#x8981;&#x5305;&#x542B;&#x5C3A;&#x5BF8;&#x4FE1;&#x606F;&#xFF1A;</p>
<p></p><div class="mathjax-exps">$$b_i = \left(\log \frac{ah_i}{AH}, \log \frac{aw_i}{AW} \right)$$</div><p></p>
<p>&#x5728;&#x4E00;&#x4E2A;&#x8BAD;&#x7EC3;&#x7684;mini-batch&#x4E2D;&#xFF0C;&#x6211;&#x4EEC;&#x7ED9;&#x5B9A;&#x4E00;&#x4E2A;&#x4E8C;&#x7EF4;<span class="mathjax-exps">$b_i$</span>&#x7684;&#x6570;&#x503C;&#xFF0C;&#x5206;&#x522B;&#x7ECF;&#x8FC7;&#x4E24;&#x5C42;&#x7684;&#x5168;&#x8FDE;&#x63A5;&#x7F51;&#x7EDC;<span class="mathjax-exps">$\mathcal{G}(b_i; w_{cls})$</span>&#x548C;<span class="mathjax-exps">$\mathcal{G}(b_i; w_{reg})$</span>&#x7684;&#x6620;&#x5C04;&#xFF0C;&#x5F97;&#x5230;&#x4E00;&#x4E2A;<span class="mathjax-exps">$W_{cls}$</span>&#x548C;<span class="mathjax-exps">$W_{reg}$</span>&#x7EF4;&#x5EA6;&#x7684;&#x53C2;&#x6570;<span class="mathjax-exps">$\theta_{cls,b_i}$</span>&#x548C;<span class="mathjax-exps">$\theta_{reg,b_i}$</span></p>
<p>&#x8BBA;&#x6587;&#x91CC;&#x9762;&#x6CA1;&#x6709;&#x7ED9;&#x51FA;&#x8FD9;&#x4E2A;&#x53C2;&#x6570;<span class="mathjax-exps">$\theta_{cls,b_i}$</span>&#x548C;<span class="mathjax-exps">$\theta_{reg,b_i}$</span>&#x5982;&#x4F55;&#x5199;&#x5165;&#x5230;Loss function&#x4E2D;&#xFF0C;&#x6211;&#x6839;&#x636E;&#x4F5C;&#x8005;&#x601D;&#x8DEF;&#x731C;&#x6D4B;&#xFF1A;</p>
<p>&#x8BBA;&#x6587;&#x63D0;&#x5230;<span class="mathjax-exps">$\mathcal{G} \left(b_i, w\right)$</span>&#x662F;&#x4E00;&#x4E2A;&#x4F4E;&#x79E9;&#x7684;&#x5B50;&#x7A7A;&#x95F4;</p>
<p>&#x4E0D;&#x8FC7;&#x6839;&#x636E;&#x8BBA;&#x6587;&#x7684;&#x6743;&#x91CD;&#x9884;&#x6D4B;&#x7684;&#x601D;&#x60F3;&#xFF0C;&#x8FD9;&#x91CC;&#x7684;&#x53C2;&#x6570;<span class="mathjax-exps">$\theta_{cls,b_i}$</span>&#x548C;<span class="mathjax-exps">$\theta_{reg,b_i}$</span>&#x5E94;&#x8BE5;&#x5728;lossfunction&#x4E2D;&#x53D1;&#x6325;&#x6743;&#x91CD;&#x7684;&#x4F5C;&#x7528;&#xFF0C;&#x5728;&#x8BAD;&#x7EC3;&#x8FC7;&#x7A0B;&#x4E2D;&#xFF0C;&#x901A;&#x8FC7;&#x7ED9;&#x5B9A;&#x4E00;&#x4E2A;&#x4F4D;&#x7F6E;&#x548C;&#x5C3A;&#x5EA6;&#x4E0B;&#x7684;anchor bbox&#x7684;&#x8F93;&#x51FA;&#x548C;&#x6807;&#x7B7E;&#xFF0C;&#x4E58;&#x4EE5;&#x76F8;&#x5E94;&#x6743;&#x91CD;&#xFF0C;&#x6765;&#x8BA1;&#x7B97;&#x8BE5;anchor&#x70B9;&#x5BF9;&#x5E94;&#x7684;&#x6240;&#x6709;anchors&#x603B;&#x7684;loss:</p>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">import</span> torch
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F

<span class="token keyword">def</span> <span class="token function">Anchor_bbox_size</span><span class="token punctuation">(</span>ah_i<span class="token punctuation">,</span>aw_i<span class="token punctuation">,</span>level<span class="token punctuation">)</span><span class="token punctuation">:</span>
        minimum_size <span class="token operator">=</span> <span class="token number">20</span>
        AH<span class="token punctuation">,</span>AW <span class="token operator">=</span> minimum_size <span class="token operator">*</span> np<span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>level<span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span>
        b_i<span class="token operator">=</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>ah_i<span class="token operator">/</span>AH<span class="token punctuation">)</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>log<span class="token punctuation">(</span>aw_i<span class="token operator">/</span>AW<span class="token punctuation">)</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> b_i
        
<span class="token keyword">def</span> <span class="token function">anchor_bbox_generator</span><span class="token punctuation">(</span>b_i<span class="token punctuation">,</span>level<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&apos;&apos;&apos;b_i = (log(ah_i/AH),log(aw_i/AW))
       b_t = [N,2]     &apos;&apos;&apos;</span>
    
    hidden_dim <span class="token operator">=</span> <span class="token number">5</span>
    theta_dim <span class="token operator">=</span> <span class="token number">10</span>
    theta_standard <span class="token operator">=</span>torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>theta_dim<span class="token punctuation">)</span>
    
    <span class="token comment">## two -layer</span>
    Residual_theta <span class="token operator">=</span>F<span class="token punctuation">.</span>linear<span class="token punctuation">(</span> F<span class="token punctuation">.</span>relu <span class="token punctuation">(</span>F<span class="token punctuation">.</span>linear<span class="token punctuation">(</span>bi<span class="token punctuation">,</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span>hidden_dim<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token punctuation">,</span> <span class="token punctuation">(</span>hidden_dim<span class="token punctuation">,</span>theta_dim <span class="token punctuation">)</span> <span class="token punctuation">)</span>
    
    theta_b_i <span class="token operator">=</span> theta_standard <span class="token operator">+</span> Residual_theta
    
    reutrn theta_b_i

<span class="token keyword">class</span> <span class="token class-name">RetinaNet</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>RetinaNet<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fpn <span class="token operator">=</span> FPN50<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>num_classes <span class="token operator">=</span> num_classes
        self<span class="token punctuation">.</span>reg_head <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_head<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>cls_head <span class="token operator">=</span> self<span class="token punctuation">.</span>_make_head<span class="token punctuation">(</span>self<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        fms <span class="token operator">=</span> self<span class="token punctuation">.</span>fpn<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        reg_preds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        cls_preds <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> fm <span class="token keyword">in</span> fms<span class="token punctuation">:</span>
            loc_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>loc_head<span class="token punctuation">(</span>fm<span class="token punctuation">)</span>
            cls_pred <span class="token operator">=</span> self<span class="token punctuation">.</span>cls_head<span class="token punctuation">(</span>fm<span class="token punctuation">)</span>
            loc_pred <span class="token operator">=</span> loc_pred<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>            <span class="token comment"># [N, 4,H,W] -&gt; [N,H,W, 4] -&gt; [N,H*W, 4]</span>
            cls_pred <span class="token operator">=</span> cls_pred<span class="token punctuation">.</span>permute<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>contiguous<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span>self<span class="token punctuation">.</span>num_classes<span class="token punctuation">)</span>  <span class="token comment"># [N,20,H,W] -&gt; [N,H,W,20] -&gt; [N,H*W,20]</span>
            loc_preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>loc_pred<span class="token punctuation">)</span>
            cls_preds<span class="token punctuation">.</span>append<span class="token punctuation">(</span>cls_pred<span class="token punctuation">)</span>
        <span class="token keyword">return</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>loc_preds<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>cls_preds<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">_make_head</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> out_planes<span class="token punctuation">)</span><span class="token punctuation">:</span>
        layers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
        <span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>ReLU<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        layers<span class="token punctuation">.</span>append<span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> out_planes<span class="token punctuation">,</span> kernel_size<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">,</span> stride<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">return</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token operator">*</span>layers<span class="token punctuation">)</span>

<span class="token keyword">def</span> <span class="token function">focal_loss_meta</span><span class="token punctuation">(</span>bi<span class="token punctuation">,</span>cls_pred<span class="token punctuation">,</span>cls_label<span class="token punctuation">,</span>reg_pred<span class="token punctuation">,</span>reg_label<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">&apos;&apos;&apos;
    bi = [N,2]
    cls_pred = [N,20]
    cls_label = [N,]
    reg_pred = [N,4]
    reg_label = [N,4]
    
    &apos;&apos;&apos;</span>
    
   
    alpha <span class="token operator">=</span> <span class="token number">0.25</span>
    gamma <span class="token operator">=</span> <span class="token number">2</span>
    num_classes <span class="token operator">=</span> <span class="token number">20</span>
    
    t <span class="token operator">=</span> torch<span class="token punctuation">.</span>eye&#xFF08;num_classes<span class="token operator">+</span><span class="token number">1</span>&#xFF09;<span class="token punctuation">(</span>cls_label<span class="token punctuation">,</span> &#xFF09;  <span class="token comment"># [N,21] 20+&#x80CC;&#x666F; </span>
    <span class="token comment"># t is one-hot vector</span>
    t <span class="token operator">=</span> t<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment"># &#x53BB;&#x6389; background &#x3010;N&#xFF0C;20&#x3011; </span>
   

    p <span class="token operator">=</span> F<span class="token punctuation">.</span>logsigmoid<span class="token punctuation">(</span>cls_pred<span class="token punctuation">)</span>
    pt <span class="token operator">=</span> p<span class="token operator">*</span>t <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>p<span class="token punctuation">)</span><span class="token operator">*</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>t<span class="token punctuation">)</span>         <span class="token comment"># pt = p if t &gt; 0 else 1-p</span>
    m <span class="token operator">=</span> alpha<span class="token operator">*</span>t <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>alpha<span class="token punctuation">)</span><span class="token operator">*</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>t<span class="token punctuation">)</span>   
    m <span class="token operator">=</span> m <span class="token operator">*</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token operator">-</span>pt<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">pow</span><span class="token punctuation">(</span>gamma<span class="token punctuation">)</span>   <span class="token comment"># focal loss &#x7CFB;&#x6570; &#x89E3;&#x51B3;&#x6837;&#x672C;&#x4E0D;&#x5E73;&#x8861;</span>
    
    weight <span class="token operator">=</span> anchor_bbox_generator<span class="token punctuation">(</span>bi<span class="token punctuation">,</span><span class="token punctuation">)</span> <span class="token comment"># [N,W] W&#x7EF4;&#x7684;&#x3B8;&#x53C2;&#x6570;&#xFF0C;&#x8BE5;&#x600E;&#x4E48;&#x7528;&#xFF1F; &#x8FD8;&#x662F;&#x8BF4;&#x8FD9;&#x91CC;W=1&#xFF1F;&#xFF1F;</span>
    
    cls_loss <span class="token operator">=</span> F<span class="token punctuation">.</span>binary_cross_entropy_with_logits<span class="token punctuation">(</span>x<span class="token punctuation">,</span> t<span class="token punctuation">,</span> m<span class="token punctuation">,</span> size_average<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    
    

</pre><p>&#x4EE5;&#x4E0A;&#x4EE3;&#x7801;&#x4EC5;&#x4EE3;&#x8868;&#x4E2A;&#x4EBA;&#x5BF9;&#x8BBA;&#x6587;&#x7684;&#x5C40;&#x9650;&#x7406;&#x89E3;</p>
<p>&#x56E0;&#x4E3A;&#x770B;&#x4E0D;&#x5230;&#x8BBA;&#x6587;&#x7684;&#x4EE3;&#x7801;&#xFF0C;&#x76EE;&#x524D;&#x6211;&#x7406;&#x89E3;&#x6700;&#x6A21;&#x7CCA;&#x7684;&#x5C31;&#x662F;&#x8FD9;&#x4E2A;&#x3B8;&#x53C2;&#x6570;&#x5982;&#x4F55;&#x4E0E;loss function&#x76F8;&#x7ED3;&#x5408;&#x7684;&#x5730;&#x65B9;&#x4E86;&#xFF0C;&#x8FD8;&#x8BF7;&#x7F51;&#x53CB;&#x591A;&#x591A;&#x4EA4;&#x6D41;&#xFF0C;&#x6B22;&#x8FCE;&#x53D1;&#x8868;&#x66F4;&#x591A;&#x7684;&#x89C1;&#x89E3;~</p>
<p>&#x4EE5;&#x4E0A;&#x57FA;&#x672C;&#x5C31;&#x4ECB;&#x7ECD;&#x4E86;&#x662F;&#x8BBA;&#x6587;&#x6700;&#x4E3B;&#x8981;&#x7684;&#x60F3;&#x6CD5;&#xFF1A;</p>
<ul>
<li>MetaAnchor&#x5BF9;&#x4E8E;anchor&#x7684;&#x8BBE;&#x5B9A;&#x548C;bbox&#x7684;&#x5206;&#x5E03;&#x66F4;&#x52A0;&#x9C81;&#x68D2;</li>
<li>MetaAnchor&#x53EF;&#x4EE5;&#x7F29;&#x51CF;&#x4E0D;&#x540C;&#x6570;&#x636E;&#x96C6;bbox&#x5206;&#x5E03;&#x7684;&#x5DEE;&#x5F02;&#x7684;&#x5F71;&#x54CD;&#xFF0C;&#x5373;&#x66F4;&#x5177;&#x8FC1;&#x79FB;&#x5B66;&#x4E60;&#x7684;&#x80FD;&#x529B;&#xFF01;</li>
</ul>
<p>&#x8BBA;&#x6587;&#x7684;&#x66F4;&#x591A;&#x7684;&#x5B9E;&#x9A8C;&#x7EC6;&#x8282;&#xFF0C;&#x6211;&#x4F1A;&#x7EE7;&#x7EED;&#x9605;&#x8BFB;&#x5E76;&#x66F4;&#x65B0;&#x535A;&#x5BA2;~</p>
<p>=========================================</p>
<p>&#x4E0A;&#x6B21;&#x535A;&#x5BA2;&#x4E2D;&#x8BF4;&#x9053;&#xFF0C;&#x6211;&#x7406;&#x89E3;&#x6700;&#x6A21;&#x7CCA;&#x7684;&#x5C31;&#x662F;&#x8FD9;&#x4E2A;&#x3B8;&#x53C2;&#x6570;&#x5982;&#x4F55;&#x4E0E;ancnhor &#x7684; loss function&#x76F8;&#x7ED3;&#x5408;&#x7684;&#x5730;&#x65B9;&#x4E86;</p>
<p>&#x6211;&#x91CD;&#x65B0;&#x9605;&#x8BFB;&#x4E86;&#x8BBA;&#x6587;&#xFF0C;&#x4F5C;&#x8005;&#x63D0;&#x5230;&#x4E86;&#x6743;&#x91CD;&#x9884;&#x6D4B;&#x7684;&#x4E3B;&#x8981;&#x53D7;&#x5230;<strong>HyperNetworks</strong>&#x7684;&#x542F;&#x53D1;,&#x7136;&#x540E;&#x6211;&#x627E;&#x6765;&#x8FD9;&#x7BC7;&#x8BBA;&#x6587;&#xFF0C;&#x521A;&#x8BFB;&#x5B8C;&#x6458;&#x8981;&#xFF0C;&#x5C31;&#x604D;&#x7136;&#x5927;&#x609F;&#x7406;&#x89E3;&#x4E86;MetaAnchor&#x91CC;&#x9884;&#x6D4B;&#x6743;&#x91CD;&#x7684;&#x601D;&#x60F3;&#xFF0C;&#x5373;&#x8FD9;&#x4E2A;&#x3B8;&#x53C2;&#x6570;&#x7684;&#x5185;&#x6DB5;&#xFF0C;<span class="mathjax-exps">$\theta_{b_i}$</span> &#x5373; <span class="mathjax-exps">$\mathcal{F}_{csl}\left(\cdot\right)$</span> &#x548C; <span class="mathjax-exps">$\mathcal{F}_{reg}\left(\cdot\right)$</span>&#x7684;&#x4E2D;&#x7684;&#x53C2;&#x6570;&#xFF0C;&#x5728;RetinaNet&#x4E2D;&#x4EE3;&#x8868;&#x4E86;&#x6700;&#x540E;&#x4E00;&#x5C42;&#x5377;&#x79EF;&#x6838;&#x7684;&#x53C2;&#x6570;&#xFF01;</p>
<h4 class="mume-header" id="%E5%8E%9F%E6%9D%A5%E6%88%91%E5%9C%A8%E8%BF%99%E4%B8%AA%E7%82%B9%E4%B8%8A%E7%90%86%E8%A7%A3%E5%9B%B0%E9%9A%BE%E7%9A%84%E5%8E%9F%E5%9B%A0%E6%98%AF%E5%A4%B4%E8%84%91%E4%B8%AD%E5%B0%91%E4%BA%86hypernetworks%E7%9A%84%E5%85%88%E9%AA%8C">&#x539F;&#x6765;&#x6211;&#x5728;&#x8FD9;&#x4E2A;&#x70B9;&#x4E0A;&#x7406;&#x89E3;&#x56F0;&#x96BE;&#x7684;&#x539F;&#x56E0;&#x662F;&#x5934;&#x8111;&#x4E2D;&#x5C11;&#x4E86;&#x201C;HyperNetworks&#x201D;&#x7684;&#x5148;&#x9A8C;&#xFF01;</h4>

<blockquote>
<p>&#x770B;&#x6765;&#x5F88;&#x591A;&#x60C5;&#x51B5;&#x4E0B;&#xFF0C;&#x6211;&#x4EEC;&#x7406;&#x89E3;&#x7684;&#x56F0;&#x96BE;&#x6E90;&#x4E8E;&#xFF1A;&#x5C11;&#x4E86;&#x67D0;&#x4E9B;&#x201C;&#x5148;&#x9A8C;&#x77E5;&#x8BC6;&#x201D;</p>
</blockquote>
<p><a href="https://arxiv.org/abs/1609.09106">HyperNetwork</a> (ICLR2017)</p>
<p>HyperNetwork&#x662F;&#x4EC0;&#x4E48;&#x5462;&#xFF0C;&#x7B80;&#x8A00;&#x4E4B;&#xFF1A;</p>
<p><strong>&#x7528;&#x4E00;&#x4E2A;&#x7F51;&#x7EDC;(A-HyperNetwork)&#x751F;&#x6210;&#x53E6;&#x5916;&#x53E6;&#x4E00;&#x4E2A;&#x7F51;&#x7EDC;(B-&#x4E3B;&#x4F53;&#x7F51;&#x7EDC;)&#x7684;&#x6743;&#x91CD;</strong></p>
<p>&#x542C;&#x8D77;&#x6765;&#x5F88;&#x795E;&#x5947;&#xFF0C;&#x56E0;&#x4E3A;&#x6211;&#x4EEC;&#x4E00;&#x822C;&#x5BF9;&#x4E8E;&#x7F51;&#x7EDC;B&#x7684;&#x5B66;&#x4E60;&#xFF0C;&#x901A;&#x5E38;&#x7ECF;&#x8FC7;&#x68AF;&#x5EA6;&#x4E0B;&#x964D;&#x6CD5;&#x4EA7;&#x751F;&#x68AF;&#x5EA6;&#x6765;&#x66F4;&#x65B0;&#x53C2;&#x6570;&#x3002;&#x800C;&#x8FD9;&#x4E2A;&#x5DE5;&#x4F5C;&#x53EF;&#x4EE5;&#x76F4;&#x63A5;&#x7528;&#x53E6;&#x4E00;&#x4E2A;&#x7F51;&#x7EDC;&#x7684;&#x8F93;&#x51FA;&#x6765;&#x9884;&#x6D4B;&#x3002;&#x8FD9;&#x6837;&#x505A;&#x7684;&#x597D;&#x5904;&#x5C31;&#x662F;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x5C06;&#x5DE8;&#x5927;&#x53C2;&#x6570;&#x91CF;&#x7684;&#x6743;&#x91CD;&#x5B66;&#x4E60;&#xFF0C;&#x8F6C;&#x6362;&#x4E3A;&#x4E00;&#x4E2A;&#x5C0F;&#x7F51;&#x7EDC;&#x7684;&#x53C2;&#x6570;&#x5B66;&#x4E60;&#xFF0C;&#x5E76;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x7AEF;&#x5230;&#x7AEF;&#x68AF;&#x5EA6;&#x4F18;&#x5316;&#x7684;&#x65B9;&#x6CD5;&#x5B66;&#x4E60;&#xFF01;</p>
<p>&#x8FD9;&#x7BC7;&#x8BBA;&#x6587;&#x5206;&#x6790;&#x4E86;LSTM&#x548C;CNN&#x4F7F;&#x7528;HyperNetwork&#x7684;&#x65B9;&#x6CD5;&#x548C;&#x6548;&#x679C;&#xFF0C;&#x7ED3;&#x5408;&#x6211;&#x4EEC;&#x4E3B;&#x8981;&#x8BBA;&#x8FF0;&#x7684;MetaAnchor&#xFF0C;&#x6211;&#x6765;&#x7B80;&#x8981;&#x4ECB;&#x7ECD;&#x4E00;&#x4E0B;Static HyperNetwork&#x5728;CNN&#x4E2D;&#x7684;&#x5E94;&#x7528;</p>
<h2 class="mume-header" id="%E9%80%9A%E8%BF%87%E4%B8%80%E4%B8%AA%E4%B8%A4%E5%B1%82%E5%85%A8%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%B0%8F%E7%BD%91%E7%BB%9C%E7%94%A8%E4%B8%80%E4%B8%AAlayer-embedding%E6%9D%A5%E9%A2%84%E6%B5%8B%E8%A1%A8%E5%BE%81cnn%E7%9A%84%E5%8D%B7%E7%A7%AF%E6%A0%B8%E5%8F%82%E6%95%B0%E5%80%BC">&#x901A;&#x8FC7;&#x4E00;&#x4E2A;&#x4E24;&#x5C42;&#x5168;&#x8FDE;&#x63A5;&#x7684;&#x5C0F;&#x7F51;&#x7EDC;&#xFF0C;&#x7528;&#x4E00;&#x4E2A;layer embedding&#x6765;&#x9884;&#x6D4B;&#xFF08;&#x8868;&#x5F81;&#xFF09;CNN&#x7684;&#x5377;&#x79EF;&#x6838;&#x53C2;&#x6570;&#x503C;</h2>

<p>&#x5BF9;&#x4E8E;&#x4E00;&#x4E2A;&#x6DF1;&#x5EA6;&#x7684;&#x5377;&#x79EF;&#x795E;&#x7ECF;&#x7F51;&#x7EDC;&#xFF0C;&#x5176;&#x53C2;&#x6570;&#x4E3B;&#x8981;&#x7531;&#x5377;&#x79EF;&#x6838;&#x6784;&#x6210;</p>
<p>&#x6BCF;&#x4E2A;&#x5377;&#x79EF;&#x6838;&#x6709; <span class="mathjax-exps">$N_{in} \times N_{out}$</span> &#x4E2A;&#x6EE4;&#x6CE2;&#x5668;  &#x6BCF;&#x4E2A;&#x6EE4;&#x6CE2;&#x5668;&#x6709; <span class="mathjax-exps">$f_{size} \times f_{size}$</span>.</p>
<p>&#x5047;&#x8BBE;&#x8FD9;&#x4E9B;&#x53C2;&#x6570;&#x5B58;&#x5728;&#x4E00;&#x4E2A;&#x77E9;&#x9635; <span class="mathjax-exps">$K^j \in \mathbb{R}^{N_{in}f_{size} \times N_{out}f_{size}}$</span> for each layer <span class="mathjax-exps">$j = 1,..,D$</span>, &#x5176;&#x4E2D; <span class="mathjax-exps">$D$</span> &#x662F;&#x5377;&#x79EF;&#x7F51;&#x7EDC;&#x7684;&#x6DF1;&#x5EA6;</p>
<p>&#x5BF9;&#x4E8E;&#x6BCF;&#x4E00;&#x5C42; <span class="mathjax-exps">$j$</span>,  hypernetwork &#x63A5;&#x53D7;&#x4E00;&#x4E2A; a layer embedding <span class="mathjax-exps">$z^j \in \mathbb{R}^{N_{z}}$</span> &#x4F5C;&#x4E3A;&#x8F93;&#x5165;&#xFF0C;&#x5E76;&#x9884;&#x6D4B; <span class="mathjax-exps">$K^j$</span>, &#x53EF;&#x4EE5;&#x5199;&#x6210;:</p>
<p></p><div class="mathjax-exps">$${K^j} = g( {z^j} ),\forall j = 1,..., D$$</div><p></p>
<p></p><div class="mathjax-exps">$${K} \in \mathbb{R}^{ N_{in}f_{size} \times N_{out}f_{size}}, {z} \in \mathbb{R}^{N_z}$$</div><p></p>
<p><img src="https://img-blog.csdnimg.cn/20181214193114742.PNG?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3Nlbml1cw==,size_16,color_FFFFFF,t_70" alt="&#x5728;&#x8FD9;&#x91CC;&#x63D2;&#x5165;&#x56FE;&#x7247;&#x63CF;&#x8FF0;"></p>
<p>&#x516C;&#x5F0F;&#x4E2D;&#xFF0C;&#x6240;&#x6709;&#x53EF;&#x5B66;&#x4E60;&#x7684;&#x53C2;&#x6570; <span class="mathjax-exps">$W_i$</span>, <span class="mathjax-exps">$B_i$</span>, <span class="mathjax-exps">$W_{out}$</span>, <span class="mathjax-exps">$B_{out}$</span> &#x5BF9;&#x4E8E;&#x6240;&#x6709; <span class="mathjax-exps">$z^{j}$</span>&#x5171;&#x4EAB;</p>
<p>&#x5728;&#x63A8;&#x7406;&#x65F6;, &#x6A21;&#x578B;&#x4EC5;&#x4EC5;&#x5C06;&#x5B66;&#x4E60;&#x5230;&#x7684; the layer embeddings <span class="mathjax-exps">$z^j$</span> &#x6765;&#x751F;&#x6210;&#x7B2C; <span class="mathjax-exps">$j$</span> &#x5C42;&#x7684;&#x5377;&#x79EF;&#x6838;&#x6743;&#x91CD;&#x53C2;&#x6570;</p>
<p>&#x8FD9;&#x5C31;&#x5C06;&#x53EF;&#x5B66;&#x4E60;&#x7684;&#x53C2;&#x6570;&#x91CF;&#x6539;&#x53D8;&#x4E86;:</p>
<p></p><div class="mathjax-exps">$$D \times N_{in} \times f_{size} \times N_{out}\times f_{size}$$</div><br>
<div class="mathjax-exps">$$\rightarrow$$</div><br>
<div class="mathjax-exps">$$N_{z}\times D + d\times (N_z + 1)\times N_i + f_{size}\times N_{out}\times f_{size}\times (d+1)$$</div><p></p>
<h4 class="mume-header" id="%E5%BA%94%E7%94%A8%E5%88%B0metaanchor%E4%B8%ADtheta_b_i%E5%8D%B3retinanet%E7%9A%84%E6%9C%80%E5%90%8E%E4%B8%80%E5%B1%82%E5%8D%B7%E7%A7%AF%E6%A0%B8%E7%9A%84%E5%8F%82%E6%95%B0">&#x5E94;&#x7528;&#x5230;MetaAnchor&#x4E2D;&#xFF1A;<span class="mathjax-exps">$\theta_{b_i}$</span>&#x5373;RetinaNet&#x7684;&#x6700;&#x540E;&#x4E00;&#x5C42;&#x5377;&#x79EF;&#x6838;&#x7684;&#x53C2;&#x6570;</h4>

<p>&#x5373;&#xFF0C;&#x6211;&#x4EEC;&#x7528;&#x81EA;&#x5B9A;&#x4E49;anchor&#x8BBE;&#x8BA1;<span class="mathjax-exps">${b_i}$</span>&#x6210;&#x4E8C;&#x7EF4;&#x5411;&#x91CF;&#xFF0C;&#x4F5C;&#x4E3A;&#x201C;layer embedding&#x201D;&#xFF0C;&#x8F93;&#x5165;&#x4E24;&#x5C42;&#x7684;&#x7F51;&#x7EDC;&#xFF0C;&#x9884;&#x6D4B;&#x4E86;RetinaNet&#x7684;&#x6700;&#x540E;&#x4E00;&#x5C42;&#x5377;&#x79EF;&#x6838;&#x53C2;&#x6570;&#x7684;&#x6B8B;&#x5DEE;&#xFF0C;&#x8FD9;&#x6837;&#x5C31;&#x964D;&#x4F4E;&#x4E86;&#x539F;RetinaNet&#x7684;&#x5377;&#x79EF;&#x6838;&#x6EE4;&#x6CE2;&#x5668;&#x7684;&#x6570;&#x91CF;&#xFF0C;&#x5C31;&#x50CF;&#x4E4B;&#x524D;&#x63D0;&#x5230;&#x7684;&#x3002;</p>
<p>&#x597D;&#x4E86;&#xFF0C;&#x6211;&#x57FA;&#x672C;&#x90FD;&#x641E;&#x6E05;&#x695A;&#x4E86;&#xFF0C;&#x4F60;&#x5462;</p>
<p>&#x540E;&#x9762;&#x4F1A;&#x7EE7;&#x7EED;&#x8D34;&#x51FA;&#x590D;&#x73B0;&#x4EE3;&#x7801;~</p>

      </div>
      
      
    
    
    
    
    
    
      <p>&nbsp;</p>
      <!--以上为修改部分 --><!--以上为修改部分 --><!--以上为修改部分 --><!--以上为修改部分 --><!--以上为修改部分 -->
      <!--以上为修改部分 --><!--以上为修改部分 --><!--以上为修改部分 --><!--以上为修改部分 --><!--以上为修改部分 -->
      
      <script type="text/javascript" src="/html_style/foot.js"></script>
      </body>
      </html>